{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e706BlX3OCK5"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, sum, avg, month, to_date\n",
        "\n",
        "# Initialize a SparkSession with the legacy time parser policy\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Sales Data Aggregation and Feature Engineering\") \\\n",
        "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Define file paths\n",
        "online_retail_data_path = \"data/Online Retail.csv\"\n",
        "\n",
        "# Define output paths\n",
        "output_path = \"output/task2\"\n",
        "\n",
        "# Load the dataset from CSV file\n",
        "online_retail_df = spark.read.csv(online_retail_data_path, header=True, inferSchema=True)\n",
        "\n",
        "# Convert date column to proper date format (adjust the date format string as necessary)\n",
        "online_retail_df = online_retail_df.withColumn(\"InvoiceDate\", to_date(col(\"InvoiceDate\"), \"MM/dd/yyyy\"))\n",
        "\n",
        "# Sales Aggregation: Total sales per product per month\n",
        "total_sales_per_product_per_month = online_retail_df.groupBy(\"StockCode\", month(\"InvoiceDate\").alias(\"month\")).agg(sum(\"Quantity\").alias(\"total_sales\"))\n",
        "total_sales_per_product_per_month.write.csv(output_path + \"/total_sales_per_product_per_month.csv\", header=True, mode=\"overwrite\")\n",
        "\n",
        "# Sales Aggregation: Average revenue per customer\n",
        "average_revenue_per_customer = online_retail_df.groupBy(\"CustomerID\").agg(avg(\"UnitPrice\").alias(\"average_revenue\"))\n",
        "average_revenue_per_customer.write.csv(output_path + \"/average_revenue_per_customer.csv\", header=True, mode=\"overwrite\")\n",
        "\n",
        "# Sales Aggregation: Seasonal patterns for top-selling products\n",
        "top_selling_products = online_retail_df.groupBy(\"StockCode\").agg(sum(\"Quantity\").alias(\"total_sales\")).orderBy(col(\"total_sales\").desc())\n",
        "top_selling_products.write.csv(output_path + \"/top_selling_products.csv\", header=True, mode=\"overwrite\")\n",
        "\n",
        "# Feature Engineering: Customer lifetime value\n",
        "customer_lifetime_value = online_retail_df.groupBy(\"CustomerID\").agg(sum(\"Quantity\").alias(\"lifetime_value\"))\n",
        "customer_lifetime_value.write.csv(output_path + \"/customer_lifetime_value.csv\", header=True, mode=\"overwrite\")\n",
        "\n",
        "# Feature Engineering: Product popularity score\n",
        "product_popularity_score = online_retail_df.groupBy(\"StockCode\").count().withColumnRenamed(\"count\", \"popularity_score\")\n",
        "product_popularity_score.write.csv(output_path + \"/product_popularity_score.csv\", header=True, mode=\"overwrite\")\n",
        "\n",
        "# Feature Engineering: Seasonal trends\n",
        "seasonal_trends = online_retail_df.groupBy(\"StockCode\", month(\"InvoiceDate\").alias(\"month\")).agg(sum(\"Quantity\").alias(\"monthly_sales\"))\n",
        "seasonal_trends.write.csv(output_path + \"/seasonal_trends.csv\", header=True, mode=\"overwrite\")\n",
        "\n",
        "# Stop the Spark session\n",
        "spark.stop()"
      ]
    }
  ]
}