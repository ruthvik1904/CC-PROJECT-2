{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vgJ58yxz8oos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b73a795a-e435-47f6-843b-c88e4fff3b59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.189.91.83)] [Connected \r                                                                                                    \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [Connected to r2u.stat.illinois.edu (192\r                                                                                                    \rHit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connected to r2u.stat.illinois.edu (192.17.190.167)] [Connect\r0% [Connecting to archive.ubuntu.com (91.189.91.82)] [Waiting for headers] [Connected to ppa.launchp\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadcontent.net (185.125.190.8\r                                                                                                    \rHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "#pyspark setup\n",
        "\n",
        "!apt-get update\n",
        "# Install Java 8 (required by Spark)\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Install Spark\n",
        "!pip install pyspark\n",
        "\n",
        "# setup environment variables\n",
        "import os\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/usr/local/lib/python3.10/dist-packages/pyspark\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HHj91RBEu-Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import Required Libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, to_timestamp, count, when, regexp_extract\n",
        "\n",
        "# Step 2: Initialize PySpark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Retail and Sentiment Analytics\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Step 3: Load Datasets\n",
        "sentiment_df = spark.read.csv(\"reviews.csv\", header=True, inferSchema=True)\n",
        "retail_df = spark.read.csv(\"Copy of Online Retail.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Step 4: Preview the Data\n",
        "print(\"Initial Data Preview - Reviews DataFrame:\")\n",
        "sentiment_df.show(5, truncate=False)\n",
        "\n",
        "print(\"Initial Data Preview - Online Retail DataFrame:\")\n",
        "retail_df.show(5, truncate=False)\n",
        "\n",
        "# Step 5: Confirm Schema\n",
        "print(\"Schema for Reviews DataFrame:\")\n",
        "sentiment_df.printSchema()\n",
        "\n",
        "print(\"Schema for Online Retail DataFrame:\")\n",
        "retail_df.printSchema()\n",
        "\n",
        "# Step 6: Handle Missing Values\n",
        "print(\"Missing values in Reviews DataFrame:\")\n",
        "sentiment_df.select([count(when(col(c).isNull(), c)).alias(c) for c in sentiment_df.columns]).show()\n",
        "\n",
        "print(\"Missing values in Online Retail DataFrame:\")\n",
        "retail_df.select([count(when(col(c).isNull(), c)).alias(c) for c in retail_df.columns]).show()\n",
        "\n",
        "# Drop rows with missing values\n",
        "sentiment_df = sentiment_df.dropna(how='any')\n",
        "retail_df = retail_df.dropna(how='any')\n",
        "\n",
        "# Step 7: Remove Duplicates\n",
        "sentiment_df = sentiment_df.dropDuplicates()\n",
        "retail_df = retail_df.dropDuplicates()\n",
        "\n",
        "# Step 8: Validate and Convert Dates in Online Retail DataFrame\n",
        "# Add a column to check if InvoiceDate is in the expected format\n",
        "retail_df = retail_df.withColumn(\n",
        "    \"ValidDate\", regexp_extract(col(\"InvoiceDate\"), r\"\\d{2}-\\d{2}-\\d{4} \\d{2}:\\d{2}\", 0)\n",
        ")\n",
        "\n",
        "# Filter out rows with invalid InvoiceDate\n",
        "invalid_dates = retail_df.filter(col(\"ValidDate\") == \"\").select(\"InvoiceDate\").distinct()\n",
        "if invalid_dates.count() > 0:\n",
        "    print(\"Rows with invalid InvoiceDate format:\")\n",
        "    invalid_dates.show()\n",
        "\n",
        "retail_df = retail_df.filter(col(\"ValidDate\") != \"\").drop(\"ValidDate\")\n",
        "\n",
        "# Convert InvoiceDate to Timestamp\n",
        "retail_df = retail_df.withColumn(\"InvoiceDate\", to_timestamp(col(\"InvoiceDate\"), \"dd-MM-yyyy HH:mm\"))\n",
        "\n",
        "# Step 9: Post-Cleansing Preview\n",
        "print(\"Data Preview after Cleansing - Reviews DataFrame:\")\n",
        "sentiment_df.show(5, truncate=False)\n",
        "\n",
        "print(\"Data Preview after Cleansing - Online Retail DataFrame:\")\n",
        "retail_df.show(5, truncate=False)\n",
        "\n",
        "# Step 10: Post-Cleansing Row Count\n",
        "print(\"Post-cleansing number of rows in Reviews DataFrame:\", sentiment_df.count())\n",
        "print(\"Post-cleansing number of rows in Online Retail DataFrame:\", retail_df.count())\n",
        "\n",
        "# Step 11: Summary Statistics for Validation\n",
        "print(\"Summary Statistics for Reviews DataFrame:\")\n",
        "sentiment_df.describe().show()\n",
        "\n",
        "print(\"Summary Statistics for Online Retail DataFrame:\")\n",
        "retail_df.describe().show()\n",
        "\n",
        "# Step 12: Additional Checks\n",
        "# Check distinct values in the Sentiment column of Reviews DataFrame\n",
        "print(\"Distinct Sentiments in Reviews DataFrame:\")\n",
        "sentiment_df.select(\"Sentiment\").distinct().show()\n",
        "\n",
        "# Check distinct countries in the Online Retail DataFrame\n",
        "print(\"Distinct Countries in Online Retail DataFrame:\")\n",
        "retail_df.select(\"Country\").distinct().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL9gauaWABIf",
        "outputId": "7d892f3b-0bd4-4b78-f8e7-e047294cb0e5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data Preview - Reviews DataFrame:\n",
            "+-------------------------------------------------------------------------------------------+---------+\n",
            "|Review                                                                                     |Sentiment|\n",
            "+-------------------------------------------------------------------------------------------+---------+\n",
            "|This product exceeded my expectations! It's high-quality and performs exceptionally well.  |Positive |\n",
            "|The product was decent. It worked fine, but it wasn't anything special.                    |Neutral  |\n",
            "|I had a terrible experience with this company. The customer service was rude and unhelpful.|Negative |\n",
            "|It's an okay product. Nothing to write home about.                                         |Neutral  |\n",
            "|Disappointed with the product. It didn't meet my expectations.                             |Negative |\n",
            "+-------------------------------------------------------------------------------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Initial Data Preview - Online Retail DataFrame:\n",
            "+---------+---------+-----------------------------------+--------+----------------+---------+----------+--------------+\n",
            "|InvoiceNo|StockCode|Description                        |Quantity|InvoiceDate     |UnitPrice|CustomerID|Country       |\n",
            "+---------+---------+-----------------------------------+--------+----------------+---------+----------+--------------+\n",
            "|536365   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER |6       |01-12-2010 08:26|2.55     |17850     |United Kingdom|\n",
            "|536365   |71053    |WHITE METAL LANTERN                |6       |01-12-2010 08:26|3.39     |17850     |United Kingdom|\n",
            "|536365   |84406B   |CREAM CUPID HEARTS COAT HANGER     |8       |01-12-2010 08:26|2.75     |17850     |United Kingdom|\n",
            "|536365   |84029G   |KNITTED UNION FLAG HOT WATER BOTTLE|6       |01-12-2010 08:26|3.39     |17850     |United Kingdom|\n",
            "|536365   |84029E   |RED WOOLLY HOTTIE WHITE HEART.     |6       |01-12-2010 08:26|3.39     |17850     |United Kingdom|\n",
            "+---------+---------+-----------------------------------+--------+----------------+---------+----------+--------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Schema for Reviews DataFrame:\n",
            "root\n",
            " |-- Review: string (nullable = true)\n",
            " |-- Sentiment: string (nullable = true)\n",
            "\n",
            "Schema for Online Retail DataFrame:\n",
            "root\n",
            " |-- InvoiceNo: string (nullable = true)\n",
            " |-- StockCode: string (nullable = true)\n",
            " |-- Description: string (nullable = true)\n",
            " |-- Quantity: integer (nullable = true)\n",
            " |-- InvoiceDate: string (nullable = true)\n",
            " |-- UnitPrice: double (nullable = true)\n",
            " |-- CustomerID: integer (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            "\n",
            "Missing values in Reviews DataFrame:\n",
            "+------+---------+\n",
            "|Review|Sentiment|\n",
            "+------+---------+\n",
            "|     0|        0|\n",
            "+------+---------+\n",
            "\n",
            "Missing values in Online Retail DataFrame:\n",
            "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
            "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
            "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
            "|        0|        0|       1342|       0|          0|        0|    104134|      0|\n",
            "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
            "\n",
            "Data Preview after Cleansing - Reviews DataFrame:\n",
            "+--------------------------------------------------+---------+\n",
            "|Review                                            |Sentiment|\n",
            "+--------------------------------------------------+---------+\n",
            "|Great product! Exceeded my expectations.          |Positive |\n",
            "|Not bad, but not great either. Just average.      |Neutral  |\n",
            "|The product quality was mediocre. Expected better.|Neutral  |\n",
            "|Incredible product! Absolutely love it.           |Positive |\n",
            "|Meh. The product was neither good nor bad.        |Neutral  |\n",
            "+--------------------------------------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Data Preview after Cleansing - Online Retail DataFrame:\n",
            "+---------+---------+----------------------------------+--------+-------------------+---------+----------+--------------+\n",
            "|InvoiceNo|StockCode|Description                       |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
            "+---------+---------+----------------------------------+--------+-------------------+---------+----------+--------------+\n",
            "|536365   |84406B   |CREAM CUPID HEARTS COAT HANGER    |8       |2010-12-01 08:26:00|2.75     |17850     |United Kingdom|\n",
            "|536406   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER|8       |2010-12-01 11:33:00|2.55     |17850     |United Kingdom|\n",
            "|536423   |22619    |SET OF 6 SOLDIER SKITTLES         |4       |2010-12-01 12:08:00|3.75     |18085     |United Kingdom|\n",
            "|536446   |22294    |HEART FILIGREE DOVE  SMALL        |48      |2010-12-01 12:15:00|1.25     |15983     |United Kingdom|\n",
            "|536520   |22241    |GARLAND WOODEN HAPPY EASTER       |2       |2010-12-01 12:43:00|1.25     |14729     |United Kingdom|\n",
            "+---------+---------+----------------------------------+--------+-------------------+---------+----------+--------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Post-cleansing number of rows in Reviews DataFrame: 131\n",
            "Post-cleansing number of rows in Online Retail DataFrame: 299861\n",
            "Summary Statistics for Reviews DataFrame:\n",
            "+-------+--------------------+---------+\n",
            "|summary|              Review|Sentiment|\n",
            "+-------+--------------------+---------+\n",
            "|  count|                 131|      131|\n",
            "|   mean|                NULL|     NULL|\n",
            "| stddev|                NULL|     NULL|\n",
            "|    min|Absolutely atroci...| Negative|\n",
            "|    max|Would not recomme...| Positive|\n",
            "+-------+--------------------+---------+\n",
            "\n",
            "Summary Statistics for Online Retail DataFrame:\n",
            "+-------+------------------+------------------+--------------------+------------------+------------------+------------------+-----------+\n",
            "|summary|         InvoiceNo|         StockCode|         Description|          Quantity|         UnitPrice|        CustomerID|    Country|\n",
            "+-------+------------------+------------------+--------------------+------------------+------------------+------------------+-----------+\n",
            "|  count|            299861|            299861|              299861|            299861|            299861|            299861|     299861|\n",
            "|   mean|   555103.80575048| 27762.06196844806|                NULL|12.639386248962019|3.5943684040290926|15263.250439370242|       NULL|\n",
            "| stddev|10436.560748751137|16953.868009070215|                NULL|197.72217958400176|  79.2361518682034|1719.1141306934423|       NULL|\n",
            "|    min|            536365|             10002| 4 PURPLE FLOCK D...|            -74215|               0.0|             12346|  Australia|\n",
            "|    max|           C571838|              POST|ZINC WIRE SWEETHE...|             74215|           38970.0|             18287|Unspecified|\n",
            "+-------+------------------+------------------+--------------------+------------------+------------------+------------------+-----------+\n",
            "\n",
            "Distinct Sentiments in Reviews DataFrame:\n",
            "+---------+\n",
            "|Sentiment|\n",
            "+---------+\n",
            "| Positive|\n",
            "|  Neutral|\n",
            "| Negative|\n",
            "+---------+\n",
            "\n",
            "Distinct Countries in Online Retail DataFrame:\n",
            "+------------------+\n",
            "|           Country|\n",
            "+------------------+\n",
            "|            Sweden|\n",
            "|         Singapore|\n",
            "|           Germany|\n",
            "|            France|\n",
            "|            Greece|\n",
            "|European Community|\n",
            "|           Belgium|\n",
            "|           Finland|\n",
            "|             Malta|\n",
            "|       Unspecified|\n",
            "|             Italy|\n",
            "|              EIRE|\n",
            "|         Lithuania|\n",
            "|            Norway|\n",
            "|             Spain|\n",
            "|           Denmark|\n",
            "|           Iceland|\n",
            "|            Israel|\n",
            "|   Channel Islands|\n",
            "|               USA|\n",
            "+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, lag, sum as F_sum, when\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "# Step 1: Aggregate data by StockCode and InvoiceDate\n",
        "daily_sales = retail_df.groupBy(\"StockCode\", \"InvoiceDate\") \\\n",
        "    .agg(F_sum(\"Quantity\").alias(\"DailySales\")) \\\n",
        "    .orderBy(\"StockCode\", \"InvoiceDate\")\n",
        "\n",
        "# Step 2: Create lag features\n",
        "window_spec = Window.partitionBy(\"StockCode\").orderBy(\"InvoiceDate\")\n",
        "for lag_value in range(1, 4):  # Creating lag1, lag2, lag3\n",
        "    daily_sales = daily_sales.withColumn(f\"lag_{lag_value}\", lag(\"DailySales\", lag_value).over(window_spec))\n",
        "\n",
        "# Step 3: Filter out rows with null lag values\n",
        "daily_sales = daily_sales.dropna()\n",
        "\n",
        "# Step 4: Assemble features and label\n",
        "feature_columns = [f\"lag_{i}\" for i in range(1, 4)]\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "daily_sales = assembler.transform(daily_sales).withColumnRenamed(\"DailySales\", \"label\")\n",
        "\n",
        "# Step 5: Scale features\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withStd=True, withMean=True)\n",
        "scaler_model = scaler.fit(daily_sales)\n",
        "daily_sales = scaler_model.transform(daily_sales)\n",
        "\n",
        "# Step 6: Split data into training and testing sets\n",
        "train_data, test_data = daily_sales.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Step 7: Build a regression model\n",
        "lr = LinearRegression(featuresCol=\"scaledFeatures\", labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "# Step 8: Hyperparameter tuning with CrossValidator\n",
        "param_grid = ParamGridBuilder() \\\n",
        "    .addGrid(lr.regParam, [0.01, 0.1, 0.5]) \\\n",
        "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
        "    .build()\n",
        "\n",
        "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "\n",
        "crossval = CrossValidator(estimator=lr,\n",
        "                          estimatorParamMaps=param_grid,\n",
        "                          evaluator=evaluator,\n",
        "                          numFolds=3)\n",
        "\n",
        "# Step 9: Train the model\n",
        "if train_data.count() > 0:\n",
        "    cv_model = crossval.fit(train_data)\n",
        "else:\n",
        "    raise ValueError(\"Training data is empty. Check your preprocessing steps!\")\n",
        "\n",
        "# Step 10: Evaluate the model\n",
        "best_model = cv_model.bestModel\n",
        "test_predictions = best_model.transform(test_data)\n",
        "\n",
        "# Step 10: Evaluate the model\n",
        "best_model = cv_model.bestModel\n",
        "\n",
        "# Print the best model parameters\n",
        "print(\"Best Model Details:\")\n",
        "print(f\" - Intercept: {best_model.intercept}\")\n",
        "print(f\" - Coefficients: {best_model.coefficients}\")\n",
        "print(f\" - Regularization Parameter (regParam): {best_model._java_obj.getRegParam()}\")\n",
        "print(f\" - ElasticNet Parameter (elasticNetParam): {best_model._java_obj.getElasticNetParam()}\")\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_predictions = best_model.transform(test_data)\n",
        "\n",
        "rmse = evaluator.evaluate(test_predictions)\n",
        "mae = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mae\").evaluate(test_predictions)\n",
        "\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "\n",
        "# Display predictions\n",
        "print(\"Test Predictions (first 10 rows):\")\n",
        "test_predictions.select(\"StockCode\", \"InvoiceDate\", \"label\", \"prediction\").show(10, truncate=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zhXJbQ6t_E_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3050645-b51d-49dc-c2f5-437b6a1e705a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model Details:\n",
            " - Intercept: 12.775064112647463\n",
            " - Coefficients: [1.0216104462881062,0.633935504452857,0.4032026125489518]\n",
            " - Regularization Parameter (regParam): 0.5\n",
            " - ElasticNet Parameter (elasticNetParam): 1.0\n",
            "Root Mean Squared Error (RMSE): 44.1066292260956\n",
            "Mean Absolute Error (MAE): 13.017012658261402\n",
            "Test Predictions (first 10 rows):\n",
            "+---------+-------------------+-----+------------------+\n",
            "|StockCode|InvoiceDate        |label|prediction        |\n",
            "+---------+-------------------+-----+------------------+\n",
            "|10002    |2010-12-08 12:24:00|12   |12.936339325047348|\n",
            "|10002    |2010-12-09 18:58:00|12   |12.736913715746129|\n",
            "|10002    |2010-12-10 12:33:00|12   |13.257888679312948|\n",
            "|10002    |2011-01-05 14:48:00|12   |12.551646606139398|\n",
            "|10002    |2011-01-16 15:50:00|6    |12.518028516462392|\n",
            "|10002    |2011-01-20 10:43:00|6    |12.7833205605585  |\n",
            "|10002    |2011-01-31 09:57:00|120  |12.732488197441771|\n",
            "|10002    |2011-02-25 09:09:00|24   |12.731580068067478|\n",
            "|10002    |2011-04-18 12:56:00|1    |13.74522809680751 |\n",
            "|10080    |2011-07-26 13:03:00|12   |12.888795411696803|\n",
            "+---------+-------------------+-----+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nSoYPeG7eVFq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}